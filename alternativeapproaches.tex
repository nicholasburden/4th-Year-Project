Machine learning is a vast field of Computer Science with many approaches demonstrating success. Here we describe some of the alternate approaches that could have been taken.

\subsection{Transformer Networks}

Transformer networks are able to process unordered sets of observations, which RNNs are unable to process effectively. Because of this, transformer networks are used extensively in natural language processing (NLP). This feature also allows for greater parallelisation than RNNs.

A transformer network consists of a set of chained encoders and a set of chained decoders. Both the encoders and decoders make use of an attention mechanism: a mechanism to use a set of encodings to incorporate context into a sequence \cite{illustratedtransformer}. An attention function can be described as mapping a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. \cite{attention}. The output is computed as a weighted sum of the values, where the weight assigned to each value is computed by a compatibility function of the query with the corresponding key \cite{attention}.

Scaled dot-product attention is a specific attenuation function with the following definition, as described in \cite{attention}:

\[
Attention(Q,K,V)=softmax(\frac{QK^T}{\sqrt{d_k}})V
\]

Where $Q$, $K$, and $V$ are the matrices containing the queries, keys, and values respectively, with $d_k$ being the dimension of the queries and keys.

Self-attention refers to the situation where the queries, keys, and values are all created using encodings of the sequence. Each encoder and decoder uses such an attention mechanism, which generates weights for each input when producing the output. Both the encoders and decoders have a feed-froward neural network for additional processing of the outputs \cite{illustratedtransformer}.

Although transformers have demonstrated great success in the field of NLP \cite{attention}, this architecture has also shown excellent results in other areas, including StarCraft II (AlphaStar used a transformer network in its architecture) \cite{alphastar}.

Therefore, this network architecture is a very promising approach in the StarCraft environment (and other similar environments) due to the network's superior ability to estimate the relevance of specific inputs in sequence data.


\subsection{Graph Convolutional Reinforcement Learning}

An alternative approach is to model the environment as a graph, as described in \cite{graph}. This builds on some of the ideas explored in this report, but formalises the relationships between agents (and other units) using a graph. Each agent is represented by a node in the graph, and each node $i$ has a set of neighbours, $\mathbb{B}_i$, which is determined by distance or other metrics \cite{graph}.

A network architecture is described in \cite{graph} for environments represented in this way, called graph  convolutional reinforcement learning, namely DGN. DGN consists of three types of modules:  observation encoder, convolutional layer and Q-network. 

DGN shares weights among all agents, making it easy to scale, and has shown great success in various game examples \cite{graph}. Therefore, applying this technique to the StarCraft II environment has a lot of potential, especially considering the successes of CNNs in this project. 

A drawback of this approach is that it is not invariant to the number of agents, since the size of the graph is defined in terms of this. A possible way to adapt this is, perhaps, to make each node a specific location in the environment, and assign weights to the edges with respect to agent locations. For example, edge $e_i = (u,v)$ has finite weight if, and only if, there are two agents close to the locations represented by nodes $u$ and $v$ respectively.



