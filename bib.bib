@book{RLAnIntro,
  added-at = {2019-07-13T10:11:53.000+0200},
  author = {Sutton, Richard S. and Barto, Andrew G.},
  biburl = {https://www.bibsonomy.org/bibtex/2f46601cf8b13d39d1378af0d79438b12/lanteunis},
  edition = {Second},
  interhash = {ac6b144aaec1819919a2fba9f705c852},
  intrahash = {f46601cf8b13d39d1378af0d79438b12},
  keywords = {},
  publisher = {The MIT Press},
  timestamp = {2019-07-13T10:11:53.000+0200},
  title = {Reinforcement Learning: An Introduction},
  url = {http://incompleteideas.net/book/the-book-2nd.html},
  year = {2018 }
}


@book{dec-pomdp,
 author = {Oliehoek, Frans A. and Amato, Christopher},
 title = {A Concise Introduction to Decentralized POMDPs},
 year = {2016},
 isbn = {3319289276, 9783319289274},
 edition = {1st},
 publisher = {Springer Publishing Company, Incorporated},
}


@misc{dqn,
    title={Playing Atari with Deep Reinforcement Learning},
    author={Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Alex Graves and Ioannis Antonoglou and Daan Wierstra and Martin Riedmiller},
    year={2013},
    eprint={1312.5602},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@phdthesis{expeirnecereplay,
 author = {Lin, Long-Ji},
 title = {Reinforcement Learning for Robots Using Neural Networks},
 year = {1992},
 note = {UMI Order No. GAX93-22750},
 publisher = {Carnegie Mellon University},
 address = {Pittsburgh, PA, USA},
}

@misc{qmix,
    title={QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning},
    author={Tabish Rashid and Mikayel Samvelyan and Christian Schroeder de Witt and Gregory Farquhar and Jakob Foerster and Shimon Whiteson},
    year={2018},
    eprint={1803.11485},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{smac,
    title={The StarCraft Multi-Agent Challenge},
    author={Mikayel Samvelyan and Tabish Rashid and Christian Schroeder de Witt and Gregory Farquhar and Nantas Nardelli and Tim G. J. Rudner and Chia-Man Hung and Philip H. S. Torr and Jakob Foerster and Shimon Whiteson},
    year={2019},
    eprint={1902.04043},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@INPROCEEDINGS{IQL,
    author = {Ming Tan},
    title = {Multi-Agent Reinforcement Learning: Independent vs. Cooperative Agents},
    booktitle = {In Proceedings of the Tenth International Conference on Machine Learning},
    year = {1993},
    pages = {330--337},
    publisher = {Morgan Kaufmann}
}

@misc{iqlisgood,
    title={Multiagent Cooperation and Competition with Deep Reinforcement Learning},
    author={Ardi Tampuu and Tambet Matiisen and Dorian Kodelja and Ilya Kuzovkin and Kristjan Korjus and Juhan Aru and Jaan Aru and Raul Vicente},
    year={2015},
    eprint={1511.08779},
    archivePrefix={arXiv},
    primaryClass={cs.AI}
}


@misc{vdn,
    title={Value-Decomposition Networks For Cooperative Multi-Agent Learning},
    author={Peter Sunehag and Guy Lever and Audrunas Gruslys and Wojciech Marian Czarnecki and Vinicius Zambaldi and Max Jaderberg and Marc Lanctot and Nicolas Sonnerat and Joel Z. Leibo and Karl Tuyls and Thore Graepel},
    year={2017},
    eprint={1706.05296},
    archivePrefix={arXiv},
    primaryClass={cs.AI}
}

@misc{hypernetworks,
    title={HyperNetworks},
    author={David Ha and Andrew Dai and Quoc V. Le},
    year={2016},
    eprint={1609.09106},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{dqrn,
    title={Deep Recurrent Q-Learning for Partially Observable MDPs},
    author={Matthew Hausknecht and Peter Stone},
    year={2015},
    eprint={1507.06527},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{coma,
    title={Counterfactual Multi-Agent Policy Gradients},
    author={Jakob Foerster and Gregory Farquhar and Triantafyllos Afouras and Nantas Nardelli and Shimon Whiteson},
    year={2017},
    eprint={1705.08926},
    archivePrefix={arXiv},
    primaryClass={cs.AI}
}


@book{cnn,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year={2016},
  publisher={MIT press}
}

@article{rnn,
  author    = {Alex Sherstinsky},
  title     = {Fundamentals of Recurrent Neural Network {(RNN)} and Long Short-Term
               Memory {(LSTM)} Network},
  journal   = {CoRR},
  volume    = {abs/1808.03314},
  year      = {2018},
  url       = {http://arxiv.org/abs/1808.03314},
  archivePrefix = {arXiv},
  eprint    = {1808.03314},
  timestamp = {Sun, 02 Sep 2018 15:01:55 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1808-03314},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{gru,
  author    = {Junyoung Chung and
               {\c{C}}aglar G{\"{u}}l{\c{c}}ehre and
               KyungHyun Cho and
               Yoshua Bengio},
  title     = {Empirical Evaluation of Gated Recurrent Neural Networks on Sequence
               Modeling},
  journal   = {CoRR},
  volume    = {abs/1412.3555},
  year      = {2014},
  url       = {http://arxiv.org/abs/1412.3555},
  archivePrefix = {arXiv},
  eprint    = {1412.3555},
  timestamp = {Mon, 13 Aug 2018 16:47:38 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/ChungGCB14},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@book{deeplearning,
 author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
 title = {Deep Learning},
 year = {2016},
 isbn = {0262035618},
 publisher = {The MIT Press}
}

@book{csmlnotes,
 author = {Ani Calinescu and Phil Blunsom},
 title = {Machine Learning - Michaelmas Term 2019 Lectures 14 - 16 :  Neural Networks}
}

@InProceedings{relu,
  title = 	 {Deep Sparse Rectifier Neural Networks},
  author = 	 {Xavier Glorot and Antoine Bordes and Yoshua Bengio},
  booktitle = 	 {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
  pages = 	 {315--323},
  year = 	 {2011},
  editor = 	 {Geoffrey Gordon and David Dunson and Miroslav Dudík},
  volume = 	 {15},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Fort Lauderdale, FL, USA},
  month = 	 {11--13 Apr},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v15/glorot11a/glorot11a.pdf},
  url = 	 {http://proceedings.mlr.press/v15/glorot11a.html},
  abstract = 	 {While logistic sigmoid neurons are more biologically plausible than hyperbolic tangent neurons, the latter work better for training multi-layer neural networks. This paper shows that rectifying neurons are an even better model of biological neurons and yield equal or better performance than hyperbolic tangent networks in spite of the hard non-linearity and non-differentiability at zero, creating sparse representations with true zeros which seem remarkably suitable for naturally sparse data. Even though they can take advantage of semi-supervised setups with extra-unlabeled data, deep rectifier networks can reach their best performance without requiring any unsupervised pre-training on purely supervised tasks with large labeled datasets. Hence, these results can be seen as a new milestone in the attempts at understanding the difficulty in training deep but purely supervised neural networks, and closing the performance gap between neural networks learnt with and without unsupervised pre-training. [pdf]}
}

@article{starcraftmicro,
  author    = {Kun Shao and
               Yuanheng Zhu and
               Dongbin Zhao},
  title     = {StarCraft Micromanagement with Reinforcement Learning and Curriculum
               Transfer Learning},
  journal   = {CoRR},
  volume    = {abs/1804.00810},
  year      = {2018},
  url       = {http://arxiv.org/abs/1804.00810},
  archivePrefix = {arXiv},
  eprint    = {1804.00810},
  timestamp = {Mon, 13 Aug 2018 16:46:46 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1804-00810},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{ddpg,
    title={Continuous control with deep reinforcement learning},
    author={Timothy P. Lillicrap and Jonathan J. Hunt and Alexander Pritzel and Nicolas Heess and Tom Erez and Yuval Tassa and David Silver and Daan Wierstra},
    year={2015},
    eprint={1509.02971},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{elu,
    title={Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)},
    author={Djork-Arné Clevert and Thomas Unterthiner and Sepp Hochreiter},
    year={2015},
    eprint={1511.07289},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{go,
  abstract = {The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses 'value networks' to evaluate board positions and 'policy networks' to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8 percent winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away.},
  added-at = {2016-05-21T09:09:48.000+0200},
  author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
  biburl = {https://www.bibsonomy.org/bibtex/29e987f58d895c490144693139cbc90c7/flint63},
  doi = {10.1038/nature16961},
  file = {Nature online:2016/SilverHuangEtAl16nature.pdf:PDF},
  groups = {public},
  interhash = {48430c7891aaf9fe2582faa8f5d076c1},
  intrahash = {9e987f58d895c490144693139cbc90c7},
  issn = {0028-0836},
  journal = {Nature},
  keywords = {01614 paper ai google learn algorithm},
  month = {#jan#},
  number = 7587,
  pages = {484--489},
  timestamp = {2018-04-16T12:03:12.000+0200},
  title = {Mastering the Game of {Go} with Deep Neural Networks and Tree Search},
  username = {flint63},
  volume = 529,
  year = 2016
}

@inproceedings{resourcemanagement,
author = {Mao, Hongzi and Alizadeh, Mohammad and Menache, Ishai and Kandula, Srikanth},
title = {Resource Management with Deep Reinforcement Learning},
year = {2016},
isbn = {9781450346610},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3005745.3005750},
doi = {10.1145/3005745.3005750},
booktitle = {Proceedings of the 15th ACM Workshop on Hot Topics in Networks},
pages = {50–56},
numpages = {7},
location = {Atlanta, GA, USA},
series = {HotNets ’16}
}

@article{traffic,
author = {Arel, Itamar and Liu, C. and Urbanik, T. and Kohls, Airton},
year = {2010},
month = {07},
pages = {128 - 135},
title = {Reinforcement learning-based multi-agent system for network traffic signal control},
volume = {4},
journal = {Intelligent Transport Systems, IET},
doi = {10.1049/iet-its.2009.0070}
}

@article{alphastar,
author = {Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech and Mathieu, Michaël and Dudzik, Andrew and Chung, Junyoung and Choi, David and Powell, Richard and Ewalds, Timo and Georgiev, Petko and Oh, Junhyuk and Horgan, Dan and Kroiss, Manuel and Danihelka, Ivo and Huang, Aja and Sifre, Laurent and Cai, Trevor and Agapiou, John and Jaderberg, Max and Silver, David},
year = {2019},
month = {11},
pages = {},
title = {Grandmaster level in StarCraft II using multi-agent reinforcement learning},
volume = {575},
journal = {Nature},
doi = {10.1038/s41586-019-1724-z}
}

  

@misc{attention,
    title={Attention Is All You Need},
    author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
    year={2017},
    eprint={1706.03762},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}



@misc{illustratedtransformer,
  title = {The Illustrated Transformer [Blog post]},
  howpublished = {\url{https://jalammar.github.io/illustrated-transformer/}},
  author={Jay Alammar},
  year={2018},
  note = {Accessed: January 2020}
}


@misc{graph,
    title={Graph Convolutional Reinforcement Learning},
    author={Jiechuan Jiang and Chen Dun and Tiejun Huang and Zongqing Lu},
    year={2018},
    eprint={1810.09202},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}


@article{natureencoder,
  added-at = {2015-08-26T14:46:40.000+0200},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  biburl = {https://www.bibsonomy.org/bibtex/2fb15f4471c81dc2b9edf2304cb2f7083/hotho},
  description = {Human-level control through deep reinforcement learning - nature14236.pdf},
  interhash = {eac59980357d99db87b341b61ef6645f},
  intrahash = {fb15f4471c81dc2b9edf2304cb2f7083},
  issn = {00280836},
  journal = {Nature},
  keywords = {deep learning toread},
  month = feb,
  number = 7540,
  pages = {529--533},
  publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  timestamp = {2015-08-26T14:46:40.000+0200},
  title = {Human-level control through deep reinforcement learning},
  url = {http://dx.doi.org/10.1038/nature14236},
  volume = 518,
  year = 2015
}


@inproceedings{lstmvsgru,
title = "Empirical evaluation of gated recurrent neural networks on sequence modeling",
author = "Junyoung Chung and Caglar Gulcehre and Kyunghyun Cho and Yoshua Bengio",
year = "2014",
language = "English (US)",
booktitle = "NIPS 2014 Workshop on Deep Learning, December 2014",

}
